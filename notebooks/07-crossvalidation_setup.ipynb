{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation data preparation\n",
    "Lots of choices to make here. One thing which stands out is the small number of timepoints. I think this is a major issue. The other way to think about the problem is to consider each county as an individual data point with 39 measurements. Then break the time series for each county into blocks and consider each on a unique data instance. The final model will be trained to make predictions for any of the counties, at any point in time, one at a time. This might be a tall order given the variation between counties, but it gives us a lot more datapoints to work with: 39 timepoints x 3,135 counties = 122,265 datapoints. Hopefully, exogenous data sources will help with the between county variability somewhat - e.g. demographic, economic or geographic data.\n",
    "\n",
    "The plan is to use a rolling origin strategy with a forecast horizon of four months and a fixed model order. We should set things up so that the model order is a optimizable parameter, but let's pick four to start. So, we will predict four future values based on four past values across the time series for each county. This does raise a concern about data leakage, as data from the first forecast will be used as input to the next block, but I think it's necessary to maximize the use of the small dataset. A few things we can do to mitigate: \n",
    "1. Keep a real out-of sample test set.\n",
    "2. Do not perform any feature engineering, smoothing or normalization on the whole dataset before the split.\n",
    "3. Randomize, randomize, randomize.\n",
    "\n",
    "Ok, enough ramble - let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.0 | packaged by conda-forge | (default, Nov 20 2021, 02:24:10) [GCC 9.4.0]\n",
      "\n",
      "NumPy: 1.23.5\n",
      "Pandas: 1.4.3\n"
     ]
    }
   ],
   "source": [
    "# Add parent directory to path to allow import of config.py\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import config as conf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(f'Python: {sys.version}')\n",
    "print()\n",
    "print(f'NumPy: {np.__version__}')\n",
    "print(f'Pandas: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>cfips</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>microbusiness_density</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_2019-08-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>3.007682</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001_2019-09-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2.884870</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001_2019-10-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.055843</td>\n",
       "      <td>1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001_2019-11-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2.993233</td>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001_2019-12-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2.993233</td>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  cfips          county    state first_day_of_month  \\\n",
       "0  1001_2019-08-01   1001  Autauga County  Alabama         2019-08-01   \n",
       "1  1001_2019-09-01   1001  Autauga County  Alabama         2019-09-01   \n",
       "2  1001_2019-10-01   1001  Autauga County  Alabama         2019-10-01   \n",
       "3  1001_2019-11-01   1001  Autauga County  Alabama         2019-11-01   \n",
       "4  1001_2019-12-01   1001  Autauga County  Alabama         2019-12-01   \n",
       "\n",
       "   microbusiness_density  active  \n",
       "0               3.007682    1249  \n",
       "1               2.884870    1198  \n",
       "2               3.055843    1269  \n",
       "3               2.993233    1243  \n",
       "4               2.993233    1243  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load up training file, set dtype for first day of month\n",
    "\n",
    "training_df = pd.read_csv(f'{conf.DATA_PATH}/train.csv.zip', compression='zip')\n",
    "training_df['first_day_of_month'] =  pd.to_datetime(training_df['first_day_of_month'])\n",
    "\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122265 entries, 0 to 122264\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   row_id                 122265 non-null  object        \n",
      " 1   cfips                  122265 non-null  int64         \n",
      " 2   county                 122265 non-null  object        \n",
      " 3   state                  122265 non-null  object        \n",
      " 4   first_day_of_month     122265 non-null  datetime64[ns]\n",
      " 5   microbusiness_density  122265 non-null  float64       \n",
      " 6   active                 122265 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(3)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "training_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, this code won't have to run many times - basically once for each model order we want to test, so it's ok if it's a little inefficient. first step will be to scan across each counties timecourse and generate input and prediction block pairs with a static size for both to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num counties: 3135\n",
      "[1001, 1003, 1005, 1007, 1009, 1011, 1013, 1015, 1017, 1019]\n"
     ]
    }
   ],
   "source": [
    "# Get list of unique cfips\n",
    "cfips_list = training_df['cfips'].drop_duplicates(keep='first').to_list()\n",
    "print(f'Num counties: {len(cfips_list)}')\n",
    "print(cfips_list[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't believe I'm only noticing this now - but I wonder if there is a reason why it seems like only odd cfips are included in the dataset? Let's ignore it for now, but definitely mental note material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of unnecessary string columns\n",
    "trimmed_training_df = training_df.drop(['row_id', 'county', 'state'], axis=1)\n",
    "\n",
    "# Convert first day of month to int\n",
    "trimmed_training_df['first_day_of_month'] =  trimmed_training_df['first_day_of_month'].astype(int)\n",
    "\n",
    "model_order = 4\n",
    "forecast_horizon = 4\n",
    "input_blocks = []\n",
    "forecast_blocks = []\n",
    "\n",
    "for cfips in cfips_list:\n",
    "    timeseries = trimmed_training_df[trimmed_training_df['cfips'] == cfips]\n",
    "    timeseries = timeseries.to_numpy()\n",
    "    # print(timeseries)\n",
    "    \n",
    "    block_count = 0\n",
    "\n",
    "    for origin in range(model_order - 1, len(timeseries) - forecast_horizon):\n",
    "        \n",
    "        block_count += 1\n",
    "\n",
    "        # print(f'Input-forecast block {block_count}')\n",
    "        # print(f'\\tInput block: {origin - model_order + 1} - {origin + 1}')\n",
    "        input_block = timeseries[(origin - model_order + 1):(origin + 1)]\n",
    "        # print(f'\\t{input_block}')\n",
    "        # print()\n",
    "        # print(f'\\tForecast block: {origin + 1} - {origin + forecast_horizon + 1}')\n",
    "        forecast_block = timeseries[(origin + 1):(origin + forecast_horizon + 1)]\n",
    "        # print(f'\\t{forecast_block}')\n",
    "        # print()\n",
    "\n",
    "        input_blocks.append(input_block)\n",
    "        forecast_blocks.append(forecast_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100320, 4, 4)\n",
      "(100320, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "input_blocks = np.array(input_blocks)\n",
    "forecast_blocks = np.array(forecast_blocks)\n",
    "print(input_blocks.shape)\n",
    "print(forecast_blocks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100320, 4, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = np.array([input_blocks, forecast_blocks])\n",
    "training_data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microbusiness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c89e0f329143aafc2740b6540b46c06e92791a1e818eb6a9ece1d952786ba476"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
