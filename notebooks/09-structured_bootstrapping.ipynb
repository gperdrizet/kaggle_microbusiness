{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 5: Structured bootstrapping\n",
    "OK, so internal benchmarking strategy #2 here. Going to start calling it bootstrapping because I am using random sampling with replacement and am envisioning a bagging approach to the final model. Big takeaway from the first cross validation-like approach (really ended up being more like bootstrapping anyway...) was that to get good approximations of the public leader board score we should not be aggregating SMAPE scores across forecast origins. This seems to result in worse performance, the explanation being that we are including data from some anomalous and some nonanomalous timepoints. When, in reality a given timepoint is either an anomaly or not. This causes the naive model to do somewhat badly all the time rather than OK on nonanomalous test time points and very badly on anomalous ones.\n",
    "\n",
    "So, the strategy here will be to structure our bootstrapping while still treating each county as an individual datapoint. To generate a sample of size n the procedure will be as follows:\n",
    "1. Remove and sequester some timepoints dataset-wide for test data.\n",
    "2. From the remaining, pick a random timepoint.\n",
    "3. From the randomly chosen timepoint randomly choose n counties.\n",
    "4. Go to step 2.\n",
    "\n",
    "This procedure could be repeated with different test-train splits, or even test train splits on non-overlapping subsets of the data. Does that make it bootstrapping inside of cross-validation fold? I don't know - I think the specific terminology here is less important than a precise description of what we are actually doing.\n",
    "\n",
    "\n",
    "1. [Abbreviations & definitions](#abbrevations_definitions)\n",
    "2. [Load & inspect](#load_inspect)\n",
    "3. [Build data structure](#build_data_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"abbreviations_definitions\"></a>\n",
    "### 1. Abbreviations & definitions\n",
    "+ MBD: microbusiness density\n",
    "+ MBC: microbusiness count\n",
    "+ OLS: ordinary least squares\n",
    "+ Model order: number of past timepoints used as input data for model training\n",
    "+ Origin (forecast origin): last known point in the input data\n",
    "+ Horizon (forecast horizon): number of future data points predicted by the model\n",
    "+ SMAPE: Symmetric mean absolute percentage error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"load_inspect\"></a>\n",
    "### 2. Load & inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.0 | packaged by conda-forge | (default, Nov 20 2021, 02:24:10) [GCC 9.4.0]\n",
      "\n",
      "Numpy 1.23.5\n",
      "Pandas 1.4.3\n"
     ]
    }
   ],
   "source": [
    "# Add parent directory to path to allow import of config.py\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import config as conf\n",
    "import functions.data_manipulation_functions as data_funcs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from statistics import NormalDist\n",
    "\n",
    "print(f'Python: {sys.version}')\n",
    "print()\n",
    "print(f'Numpy {np.__version__}')\n",
    "print(f'Pandas {pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cfips</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>microbusiness_density</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>1564617600000000000</td>\n",
       "      <td>3.007682</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>1567296000000000000</td>\n",
       "      <td>2.884870</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>1569888000000000000</td>\n",
       "      <td>3.055843</td>\n",
       "      <td>1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>1572566400000000000</td>\n",
       "      <td>2.993233</td>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1575158400000000000</td>\n",
       "      <td>2.993233</td>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cfips   first_day_of_month  microbusiness_density  active\n",
       "0   1001  1564617600000000000               3.007682    1249\n",
       "1   1001  1567296000000000000               2.884870    1198\n",
       "2   1001  1569888000000000000               3.055843    1269\n",
       "3   1001  1572566400000000000               2.993233    1243\n",
       "4   1001  1575158400000000000               2.993233    1243"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load up training file, set dtype for first day of month\n",
    "training_df = pd.read_csv(f'{conf.KAGGLE_DATA_PATH}/train.csv.zip', compression='zip')\n",
    "training_df['first_day_of_month'] =  pd.to_datetime(training_df['first_day_of_month']).astype(int)\n",
    "training_df.drop(['row_id', 'county','state'], axis=1, inplace=True)\n",
    "training_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"build_data_structure\"></a>\n",
    "### 1. Build data structure\n",
    "First thing to do is build a data structure that will make resampling as easy as possible and persist it to disk. Then we will implement resampling. This way when experimenting with/training models, it will be easy to generate samples on they fly without having to rebuild the whole thing in memory each time.\n",
    "\n",
    "The trick here is that in the first dimension we want the timepoints, then the counties, then the data columns. But, the 'timepoints' we want in the first dimension are really the forecast origins for a subset of the timecourse.\n",
    "\n",
    "Maybe the best way to think about it is to forget the model order, forecast horizon and forecast origin location for now and just pick a data instance size. Then, when feeding the sample to a model we can break each block into input and forecast halves on the fly however we want. This will also solve the problem we had in notebook #07 where if model order != forecast horizon NumPy complains about ragged arrays.\n",
    "\n",
    "Not sure if there maybe would be a speed advantage of sharding the data to multiple files here - i.e. each timepoint gets its own file and then worker processes can be assigned to sample from and train on the timepoints independently. Let's save that for a later optimization to minimize complexity out of the gate and not spend time prematurely optimizing something that ends up not being the right idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cfips</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>microbusiness_density</th>\n",
       "      <th>active</th>\n",
       "      <th>timepoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>1564617600000000000</td>\n",
       "      <td>3.007682</td>\n",
       "      <td>1249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>1567296000000000000</td>\n",
       "      <td>2.884870</td>\n",
       "      <td>1198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>1569888000000000000</td>\n",
       "      <td>3.055843</td>\n",
       "      <td>1269</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>1572566400000000000</td>\n",
       "      <td>2.993233</td>\n",
       "      <td>1243</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1575158400000000000</td>\n",
       "      <td>2.993233</td>\n",
       "      <td>1243</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cfips   first_day_of_month  microbusiness_density  active  timepoint\n",
       "0   1001  1564617600000000000               3.007682    1249          0\n",
       "1   1001  1567296000000000000               2.884870    1198          1\n",
       "2   1001  1569888000000000000               3.055843    1269          2\n",
       "3   1001  1572566400000000000               2.993233    1243          3\n",
       "4   1001  1575158400000000000               2.993233    1243          4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First thing, let's give each timepoint an integer number so we don't have to \n",
    "# work with the strings/datetimes in 'first_day_of_month' directly and clean up\n",
    "# columns we won't need.\n",
    "\n",
    "training_df['timepoint'] = training_df.groupby(['cfips']).cumcount()\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num counties: 3135\n",
      "Num timepoints: 39\n",
      "\n",
      "\tBlock range: 0 - 8\n",
      "\tBlock range: 1 - 9\n",
      "\tBlock range: 2 - 10\n",
      "\tBlock range: 3 - 11\n",
      "\tBlock range: 4 - 12\n",
      "\tBlock range: 5 - 13\n",
      "\tBlock range: 6 - 14\n",
      "\tBlock range: 7 - 15\n",
      "\tBlock range: 8 - 16\n",
      "\tBlock range: 9 - 17\n",
      "\tBlock range: 10 - 18\n",
      "\tBlock range: 11 - 19\n",
      "\tBlock range: 12 - 20\n",
      "\tBlock range: 13 - 21\n",
      "\tBlock range: 14 - 22\n",
      "\tBlock range: 15 - 23\n",
      "\tBlock range: 16 - 24\n",
      "\tBlock range: 17 - 25\n",
      "\tBlock range: 18 - 26\n",
      "\tBlock range: 19 - 27\n",
      "\tBlock range: 20 - 28\n",
      "\tBlock range: 21 - 29\n",
      "\tBlock range: 22 - 30\n",
      "\tBlock range: 23 - 31\n",
      "\tBlock range: 24 - 32\n",
      "\tBlock range: 25 - 33\n",
      "\tBlock range: 26 - 34\n",
      "\tBlock range: 27 - 35\n",
      "\tBlock range: 28 - 36\n",
      "\tBlock range: 29 - 37\n",
      "\tBlock range: 30 - 38\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "\n",
    "# Going to need a list of unique cfips IDs to retrieve the counties\n",
    "cfips_list = training_df['cfips'].drop_duplicates(keep='first').to_list()\n",
    "print(f'Num counties: {len(cfips_list)}')\n",
    "\n",
    "# The possible block left edges are the timepoints so loop on those\n",
    "num_timepoints = training_df['timepoint'].nunique()\n",
    "print(f'Num timepoints: {num_timepoints}\\n')\n",
    "\n",
    "timepoints = []\n",
    "\n",
    "for left_edge in range(num_timepoints - block_size):\n",
    "\n",
    "    # The right edge of this block is the left edge number\n",
    "    # plus the blocksize\n",
    "    right_edge = left_edge + block_size\n",
    "    print(f'\\tBlock range: {left_edge} - {right_edge}')\n",
    "\n",
    "    # Holder for individual blocks\n",
    "    blocks = []\n",
    "\n",
    "    # Now we go through each county and get this block range\n",
    "    for cfips in cfips_list:\n",
    "\n",
    "        # Get data for just this county\n",
    "        county_data = training_df[training_df['cfips'] == cfips]\n",
    "\n",
    "        # Get rows for the block range\n",
    "        county_data = county_data.loc[(county_data['timepoint'] >= left_edge) & (county_data['timepoint'] < right_edge)]\n",
    "\n",
    "        # Convert block range rows to numpy and collect\n",
    "        blocks.append(county_data.to_numpy())\n",
    "    \n",
    "    # Convert list of blocks to numpy and collect\n",
    "    timepoints.append(np.array(blocks))\n",
    "\n",
    "# Convert final result to numpy\n",
    "timepoints = np.array(timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timepoints shape: (31, 3135, 8, 5)\n",
      "\n",
      "Column types:\n",
      "\t<class 'numpy.float64'>\n",
      "\t<class 'numpy.float64'>\n",
      "\t<class 'numpy.float64'>\n",
      "\t<class 'numpy.float64'>\n",
      "\t<class 'numpy.float64'>\n",
      "\n",
      "Example block:\n",
      "[[1.0010000e+03 1.5646176e+18 3.0076818e+00 1.2490000e+03 0.0000000e+00]\n",
      " [1.0010000e+03 1.5672960e+18 2.8848701e+00 1.1980000e+03 1.0000000e+00]\n",
      " [1.0010000e+03 1.5698880e+18 3.0558431e+00 1.2690000e+03 2.0000000e+00]\n",
      " [1.0010000e+03 1.5725664e+18 2.9932332e+00 1.2430000e+03 3.0000000e+00]\n",
      " [1.0010000e+03 1.5751584e+18 2.9932332e+00 1.2430000e+03 4.0000000e+00]\n",
      " [1.0010000e+03 1.5778368e+18 2.9690900e+00 1.2420000e+03 5.0000000e+00]\n",
      " [1.0010000e+03 1.5805152e+18 2.9093256e+00 1.2170000e+03 6.0000000e+00]\n",
      " [1.0010000e+03 1.5830208e+18 2.9332314e+00 1.2270000e+03 7.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Timepoints shape: {timepoints.shape}')\n",
    "print()\n",
    "print('Column types:')\n",
    "\n",
    "for column in timepoints[0,0,0,0:]:\n",
    "    print(f'\\t{type(column)}')\n",
    "\n",
    "print()\n",
    "print(f'Example block:\\n{timepoints[0,0,0:,]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, looks good. We could use int for some of these columns, but we need float for the MBD, so let's leave it alone rather than using mixed types in a NumPy array. So, that's it - easy. Let's round trip it and try recovering some our values back into a nice pandas dataframe as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timepoints shape: (31, 3135, 8, 5)\n",
      "Example block:\n",
      "[[1.0010000e+03 1.5646176e+18 3.0076818e+00 1.2490000e+03 0.0000000e+00]\n",
      " [1.0010000e+03 1.5672960e+18 2.8848701e+00 1.1980000e+03 1.0000000e+00]\n",
      " [1.0010000e+03 1.5698880e+18 3.0558431e+00 1.2690000e+03 2.0000000e+00]\n",
      " [1.0010000e+03 1.5725664e+18 2.9932332e+00 1.2430000e+03 3.0000000e+00]\n",
      " [1.0010000e+03 1.5751584e+18 2.9932332e+00 1.2430000e+03 4.0000000e+00]\n",
      " [1.0010000e+03 1.5778368e+18 2.9690900e+00 1.2420000e+03 5.0000000e+00]\n",
      " [1.0010000e+03 1.5805152e+18 2.9093256e+00 1.2170000e+03 6.0000000e+00]\n",
      " [1.0010000e+03 1.5830208e+18 2.9332314e+00 1.2270000e+03 7.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Write to disk\n",
    "output_file = f'{conf.DATA_PATH}/parsed_data/structured_bootstrap_blocksize{block_size}.npy'\n",
    "np.save(output_file, timepoints)\n",
    "\n",
    "# Check round-trip\n",
    "loaded_timepoints = np.load(output_file)\n",
    "\n",
    "# Inspect\n",
    "print(f'Timepoints shape: {loaded_timepoints.shape}')\n",
    "print(f'Example block:\\n{loaded_timepoints[0,0,0:,]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, not surprisingly - we got the same thing back. Last thing to do before we call this done is to test if we can get our dates, row_ids and cfips back into a format that matches the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dates: [1.5646176e+18 1.5672960e+18 1.5698880e+18 1.5725664e+18 1.5751584e+18\n",
      " 1.5778368e+18 1.5805152e+18 1.5830208e+18]\n",
      "dtype: <class 'numpy.ndarray'>\n",
      "element dtype: <class 'numpy.float64'>\n",
      "\n",
      "Test dates: [1564617600000000000 1567296000000000000 1569888000000000000\n",
      " 1572566400000000000 1575158400000000000 1577836800000000000\n",
      " 1580515200000000000 1583020800000000000]\n",
      "dtype: <class 'numpy.ndarray'>\n",
      "element dtype: <class 'numpy.int64'>\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 1 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   first_day_of_month  8 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 192.0 bytes\n"
     ]
    }
   ],
   "source": [
    "# Grab an example date column\n",
    "test_dates = loaded_timepoints[0,0,0:,1] # type: ignore\n",
    "print(f'Test dates: {test_dates}\\ndtype: {type(test_dates)}\\nelement dtype: {type(test_dates[0])}\\n')\n",
    "\n",
    "# Cast float64 to int64\n",
    "test_dates = test_dates.astype(np.int64)\n",
    "print(f'Test dates: {test_dates}\\ndtype: {type(test_dates)}\\nelement dtype: {type(test_dates[0])}\\n')\n",
    "\n",
    "# Convert to pandas dataframe with dtype datetime64[ns] and column name 'first_day_of_month'\n",
    "test_dates_df = pd.DataFrame(pd.to_datetime(test_dates), columns=['first_day_of_month']).astype('datetime64')\n",
    "test_dates_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_day_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_day_of_month\n",
       "0         2019-08-01\n",
       "1         2019-09-01\n",
       "2         2019-10-01\n",
       "3         2019-11-01\n",
       "4         2019-12-01"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cfips: [1001. 1001. 1001. 1001. 1001. 1001. 1001. 1001.]\n",
      "dtype: <class 'numpy.ndarray'>\n",
      "element dtype: <class 'numpy.float64'>\n",
      "\n",
      "Test cfips: [1001 1001 1001 1001 1001 1001 1001 1001]\n",
      "dtype: <class 'numpy.ndarray'>\n",
      "element dtype: <class 'numpy.int64'>\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   cfips   8 non-null      int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 192.0 bytes\n"
     ]
    }
   ],
   "source": [
    "# Grab an example cfips column\n",
    "test_cfips = loaded_timepoints[0,0,0:,0] # type: ignore\n",
    "print(f'Test cfips: {test_cfips}\\ndtype: {type(test_cfips)}\\nelement dtype: {type(test_cfips[0])}\\n')\n",
    "\n",
    "# Cast float64 to int64\n",
    "test_cfips = test_cfips.astype(np.int64)\n",
    "print(f'Test cfips: {test_cfips}\\ndtype: {type(test_cfips)}\\nelement dtype: {type(test_cfips[0])}\\n')\n",
    "\n",
    "# Convert to pandas dataframe with dtype int64 and column name 'cfips'\n",
    "test_cfips_df = pd.DataFrame(test_cfips, columns=['cfips']).astype('int64')\n",
    "test_cfips_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cfips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cfips\n",
       "0   1001\n",
       "1   1001\n",
       "2   1001\n",
       "3   1001\n",
       "4   1001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cfips_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, happy - making the rwo ID is just a string join from here, so no problem. An if for some reason we want the string county or state back, we can use a CFIPS lookup table. Time to move on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microbusiness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c89e0f329143aafc2740b6540b46c06e92791a1e818eb6a9ece1d952786ba476"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
