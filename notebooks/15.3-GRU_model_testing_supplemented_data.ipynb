{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU model testing: detrended data\n",
    "Next thing to try is detrended data input for our semi-optimized GRU. Only big difference here will be a rework of SMAPE scoring to take predicted changes, and convert them back into MBD values of SMAPE scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add notebook parent dir to path so we can import from functions/\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project config file\n",
    "import config as conf\n",
    "\n",
    "# Import notebooks specific helper functions\n",
    "import functions.notebook_helper_functions.notebook15 as funcs\n",
    "import functions.initialization_functions as init_funcs\n",
    "\n",
    "# Instantiate paths and model parameters\n",
    "paths = conf.DataFilePaths()\n",
    "params = conf.GRU_model_parameters()\n",
    "\n",
    "# Load data column index\n",
    "index = shelve.open(paths.PARSED_DATA_COLUMN_INDEX)\n",
    "\n",
    "# Fire up logger\n",
    "logger = init_funcs.start_logger(\n",
    "    logfile = f'{paths.LOG_DIR}/{params.log_file_name}',\n",
    "    logstart_msg = 'Starting GRU hyperparameter optimization run'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input data shape: (15, 3135, 25, 6)\n",
      "\n",
      "Input data column index:\n",
      "cfips: 0\n",
      "first_day_of_month: 1\n",
      "microbusiness_density: 2\n",
      "active: 3\n",
      "microbusiness_density_change: 4\n",
      "microbusiness_density_change_change: 5\n"
     ]
    }
   ],
   "source": [
    "# Load data with block size\n",
    "input_file = f'{paths.PARSED_DATA_PATH}/{params.input_file_root_name}25.npy'\n",
    "timepoints = np.load(input_file)\n",
    "\n",
    "# Print some info.\n",
    "print()\n",
    "print(f'Input data shape: {timepoints.shape}')\n",
    "print()\n",
    "\n",
    "print('Input data column index:')\n",
    "\n",
    "for column, num in index.items():\n",
    "    print(f'{column}: {num}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimensions here are:\n",
    "\n",
    "0. The timepoint block - the size of this axis depends on the width of the block used to scan the data - smaller blocks give more timepoints with num_timepoint_blocks = total_timepoints - block_size + 1. This is also the axis we need to do our training validation split on. First part becomes training, last part becomes validation.\n",
    "1. The counties - each element here is a county, for the purposes of our first experiment we will treat each county as a batch.\n",
    "2. The the timepoints in the timepoint block (~row in pandas dataframe).\n",
    "3. The features (~column in pandas dataframe). To start with, we will work with one feature only - the microbusiness density.\n",
    "\n",
    "First up - training/validation/testing split, followed by data standardization and then an axis swap to make the data batch major as is the convention for tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (3135, 7, 25, 1)\n",
      "validation data shape: (3135, 3, 25, 1)\n"
     ]
    }
   ],
   "source": [
    "datasets = funcs.training_validation_testing_split(\n",
    "    index,\n",
    "    timepoints,\n",
    "    num_counties = params.num_counties,\n",
    "    input_data_type = 'microbusiness_density_change_change',\n",
    "    testing_timepoints = params.testing_timepoints,\n",
    "    training_split_fraction = params.training_split_fraction,\n",
    "    pad_validation_data = params.pad_validation_data,\n",
    "    forecast_horizon = params.forecast_horizon\n",
    ")\n",
    "\n",
    "datasets, training_mean, training_deviation = funcs.standardize_datasets(datasets)\n",
    "datasets = funcs.make_batch_major(datasets)\n",
    "\n",
    "for data_type, data in datasets.items():\n",
    "    print(f'{data_type} data shape: {data.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Let's build the model. Only additional thing to mention here is that for each time block in the counties, the first n - 5 datapoints are the time ordered input and the last five is the value we are trying to predict. With that in mind, let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3134/3135 [============================>.] - ETA: 0s - loss: 0.0203 - MAE: 0.0370\n",
      "Epoch 1: val_loss improved from inf to 1.35164, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 34s 10ms/step - loss: 0.0203 - MAE: 0.0370 - val_loss: 1.3516 - val_MAE: 0.0570\n",
      "Epoch 2/20\n",
      "3134/3135 [============================>.] - ETA: 0s - loss: 0.0200 - MAE: 0.0366\n",
      "Epoch 2: val_loss improved from 1.35164 to 1.34769, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 29s 9ms/step - loss: 0.0200 - MAE: 0.0366 - val_loss: 1.3477 - val_MAE: 0.0566\n",
      "Epoch 3/20\n",
      "3132/3135 [============================>.] - ETA: 0s - loss: 0.0198 - MAE: 0.0364\n",
      "Epoch 3: val_loss improved from 1.34769 to 1.34395, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 29s 9ms/step - loss: 0.0198 - MAE: 0.0364 - val_loss: 1.3440 - val_MAE: 0.0563\n",
      "Epoch 4/20\n",
      "3133/3135 [============================>.] - ETA: 0s - loss: 0.0196 - MAE: 0.0363\n",
      "Epoch 4: val_loss improved from 1.34395 to 1.34138, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 29s 9ms/step - loss: 0.0196 - MAE: 0.0363 - val_loss: 1.3414 - val_MAE: 0.0560\n",
      "Epoch 5/20\n",
      "3135/3135 [==============================] - ETA: 0s - loss: 0.0195 - MAE: 0.0362\n",
      "Epoch 5: val_loss improved from 1.34138 to 1.33958, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 30s 10ms/step - loss: 0.0195 - MAE: 0.0362 - val_loss: 1.3396 - val_MAE: 0.0558\n",
      "Epoch 6/20\n",
      "3128/3135 [============================>.] - ETA: 0s - loss: 0.0184 - MAE: 0.0357\n",
      "Epoch 6: val_loss improved from 1.33958 to 1.33840, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 30s 10ms/step - loss: 0.0194 - MAE: 0.0362 - val_loss: 1.3384 - val_MAE: 0.0557\n",
      "Epoch 7/20\n",
      "3130/3135 [============================>.] - ETA: 0s - loss: 0.0193 - MAE: 0.0361\n",
      "Epoch 7: val_loss improved from 1.33840 to 1.33764, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 30s 10ms/step - loss: 0.0193 - MAE: 0.0362 - val_loss: 1.3376 - val_MAE: 0.0555\n",
      "Epoch 8/20\n",
      "3127/3135 [============================>.] - ETA: 0s - loss: 0.0182 - MAE: 0.0357\n",
      "Epoch 8: val_loss improved from 1.33764 to 1.33713, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 30s 9ms/step - loss: 0.0192 - MAE: 0.0362 - val_loss: 1.3371 - val_MAE: 0.0554\n",
      "Epoch 9/20\n",
      "3127/3135 [============================>.] - ETA: 0s - loss: 0.0182 - MAE: 0.0357\n",
      "Epoch 9: val_loss improved from 1.33713 to 1.33675, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 29s 9ms/step - loss: 0.0192 - MAE: 0.0362 - val_loss: 1.3368 - val_MAE: 0.0553\n",
      "Epoch 10/20\n",
      "3129/3135 [============================>.] - ETA: 0s - loss: 0.0191 - MAE: 0.0362\n",
      "Epoch 10: val_loss improved from 1.33675 to 1.33644, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 29s 9ms/step - loss: 0.0191 - MAE: 0.0362 - val_loss: 1.3364 - val_MAE: 0.0552\n",
      "Epoch 11/20\n",
      "3133/3135 [============================>.] - ETA: 0s - loss: 0.0191 - MAE: 0.0363\n",
      "Epoch 11: val_loss improved from 1.33644 to 1.33615, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 28s 9ms/step - loss: 0.0191 - MAE: 0.0363 - val_loss: 1.3361 - val_MAE: 0.0552\n",
      "Epoch 12/20\n",
      "3135/3135 [==============================] - ETA: 0s - loss: 0.0190 - MAE: 0.0363\n",
      "Epoch 12: val_loss improved from 1.33615 to 1.33587, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 29s 9ms/step - loss: 0.0190 - MAE: 0.0363 - val_loss: 1.3359 - val_MAE: 0.0551\n",
      "Epoch 13/20\n",
      "3127/3135 [============================>.] - ETA: 0s - loss: 0.0180 - MAE: 0.0358\n",
      "Epoch 13: val_loss improved from 1.33587 to 1.33561, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 28s 9ms/step - loss: 0.0189 - MAE: 0.0363 - val_loss: 1.3356 - val_MAE: 0.0551\n",
      "Epoch 14/20\n",
      "3131/3135 [============================>.] - ETA: 0s - loss: 0.0189 - MAE: 0.0363\n",
      "Epoch 14: val_loss improved from 1.33561 to 1.33536, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 30s 10ms/step - loss: 0.0189 - MAE: 0.0363 - val_loss: 1.3354 - val_MAE: 0.0552\n",
      "Epoch 15/20\n",
      "3135/3135 [==============================] - ETA: 0s - loss: 0.0188 - MAE: 0.0363\n",
      "Epoch 15: val_loss improved from 1.33536 to 1.33515, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 31s 10ms/step - loss: 0.0188 - MAE: 0.0363 - val_loss: 1.3352 - val_MAE: 0.0554\n",
      "Epoch 16/20\n",
      "3134/3135 [============================>.] - ETA: 0s - loss: 0.0188 - MAE: 0.0363\n",
      "Epoch 16: val_loss improved from 1.33515 to 1.33501, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 31s 10ms/step - loss: 0.0188 - MAE: 0.0363 - val_loss: 1.3350 - val_MAE: 0.0558\n",
      "Epoch 17/20\n",
      "3129/3135 [============================>.] - ETA: 0s - loss: 0.0187 - MAE: 0.0363\n",
      "Epoch 17: val_loss improved from 1.33501 to 1.33496, saving model to /home/siderealyear/arkk/kaggle_microbusiness/logs/model_checkpoints/GRU_hyperparameter_optimization/detrended_data_test/GRU_units-64_learning_rate-0.0001/winner.ckpt\n",
      "3135/3135 [==============================] - 32s 10ms/step - loss: 0.0187 - MAE: 0.0363 - val_loss: 1.3350 - val_MAE: 0.0561\n",
      "Epoch 18/20\n",
      "1791/3135 [================>.............] - ETA: 8s - loss: 0.0220 - MAE: 0.0369"
     ]
    }
   ],
   "source": [
    "model, history = funcs.train_GRU(\n",
    "    datasets,\n",
    "    forecast_horizon = 5,\n",
    "    epochs = 20,\n",
    "    GRU_units = 64,\n",
    "    learning_rate = 0.0001,\n",
    "    save_tensorboard_log = params.save_tensorboard_log,\n",
    "    tensorboard_log_dir = params.tensorboard_log_dir,\n",
    "    tensorboard_histogram_freq = params.tensorboard_histogram_freq,\n",
    "    save_model_checkpoints = params.save_model_checkpoints,\n",
    "    model_checkpoint_dir = params.model_checkpoint_dir,\n",
    "    model_checkpoint_threshold = params.model_checkpoint_threshold,\n",
    "    model_checkpoint_variable = params.model_checkpoint_variable,\n",
    "    early_stopping = params.early_stopping,\n",
    "    early_stopping_monitor = params.early_stopping_monitor,\n",
    "    early_stopping_min_delta = params.early_stopping_min_delta,\n",
    "    early_stopping_patience = params.early_stopping_patience,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Plot and label the training and validation MSE (loss)\n",
    "ax[0].plot(list(range(len(history.history['loss']))), history.history['loss'], c='black', label='Training Loss')\n",
    "ax[0].plot(list(range(len(history.history['val_loss']))), history.history['val_loss'], c='red', label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "ax[0].set_title('Mean square error')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "\n",
    "# Plot and label the training and validation MAE\n",
    "ax[1].plot(list(range(len(history.history['MAE']))), history.history['MAE'], c='black', label='Training Loss')\n",
    "ax[1].plot(list(range(len(history.history['val_MAE']))), history.history['val_MAE'], c='red', label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "ax[1].set_title('Mean absolute error')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, targets = funcs.make_predictions(\n",
    "    model, \n",
    "    datasets, \n",
    "    params.forecast_horizon, \n",
    "    training_mean, \n",
    "    training_deviation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs actual MBD values for validation set\n",
    "\n",
    "# Set common axis limits\n",
    "data_pool = list(targets['validation'].flatten()) + list(predictions['GRU_validation'].flatten())\n",
    "trimmed_data_pool = [i for i in data_pool if i > 0]\n",
    "\n",
    "plot_max = max(trimmed_data_pool)\n",
    "plot_min = min(trimmed_data_pool)\n",
    "\n",
    "# Make plots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Plot with linear axes\n",
    "ax[0].scatter(targets['validation'].flatten(), predictions['GRU_validation'].flatten(), s=params.plot_point_size, c='red')\n",
    "\n",
    "# Add y=x line\n",
    "ax[0].axline((plot_min, plot_min), (plot_max, plot_max), color='black', linestyle='dashed')\n",
    "\n",
    "# Set axis limits\n",
    "ax[0].set_xlim([plot_min, plot_max])\n",
    "ax[0].set_ylim([plot_min, plot_max])\n",
    "\n",
    "# Add labels\n",
    "ax[0].set_xlabel('Actual change in MBD')\n",
    "ax[0].set_ylabel('Predicted change in MBD')\n",
    "\n",
    "# Plot again with log10 axes\n",
    "ax[1].scatter(targets['validation'].flatten(), predictions['GRU_validation'].flatten(), s=params.plot_point_size, c='red')\n",
    "\n",
    "# Add y=x line\n",
    "ax[1].axline((plot_min, plot_min), (plot_max, plot_max), color='black', linestyle='dashed')\n",
    "\n",
    "# Set axis limits\n",
    "ax[1].set_xlim([plot_min, plot_max])\n",
    "ax[1].set_ylim([plot_min, plot_max])\n",
    "\n",
    "# Add labels\n",
    "ax[1].set_xlabel('Actual change in MBD')\n",
    "ax[1].set_ylabel('Predicted change in MBD')\n",
    "\n",
    "# Set log10 scales\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_yscale('log')\n",
    "\n",
    "# Add in main title\n",
    "plt.suptitle('Predicted vs. actual validation microbusiness density change')\n",
    " \n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split off the last three individual month's predictions\n",
    "# this approximates the final private leaderboard scoring\n",
    "index_3_validation_predictions = predictions['GRU_validation'][:,2]\n",
    "index_4_validation_predictions = predictions['GRU_validation'][:,3]\n",
    "index_5_validation_predictions = predictions['GRU_validation'][:,4]\n",
    "\n",
    "index_3_validation_targets = targets['validation'][:,2]\n",
    "index_4_validation_targets = targets['validation'][:,3]\n",
    "index_5_validation_targets = targets['validation'][:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs actual MBD values for validation set by the forecast horizon index\n",
    "\n",
    "# Set common axis limits\n",
    "data_pool = list(targets['validation'].flatten()) + list(predictions['GRU_validation'].flatten())\n",
    "trimmed_data_pool = [i for i in data_pool if i > 0]\n",
    "\n",
    "plot_max = max(trimmed_data_pool)\n",
    "plot_min = min(trimmed_data_pool)\n",
    "\n",
    "# Make plots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Plot with linear axes\n",
    "ax[0].scatter(index_3_validation_targets, index_3_validation_predictions, s=params.plot_point_size, label='+3')\n",
    "ax[0].scatter(index_4_validation_targets, index_4_validation_predictions, s=params.plot_point_size, label='+4')\n",
    "ax[0].scatter(index_5_validation_targets, index_5_validation_predictions, s=params.plot_point_size, label='+5')\n",
    "\n",
    "# Add y=x line\n",
    "ax[0].axline((plot_min, plot_min), (plot_max, plot_max), color='black', linestyle='dashed')\n",
    "\n",
    "# Set axis limits\n",
    "ax[0].set_xlim([plot_min, plot_max])\n",
    "ax[0].set_ylim([plot_min, plot_max])\n",
    "\n",
    "# Add labels\n",
    "ax[0].set_xlabel('Actual change in MBD')\n",
    "ax[0].set_ylabel('Predicted change in MBD')\n",
    "\n",
    "# Plot again with log10 axes\n",
    "ax[1].scatter(index_3_validation_targets, index_3_validation_predictions, s=params.plot_point_size, label='+3')\n",
    "ax[1].scatter(index_4_validation_targets, index_4_validation_predictions, s=params.plot_point_size, label='+4')\n",
    "ax[1].scatter(index_5_validation_targets, index_5_validation_predictions, s=params.plot_point_size, label='+5')\n",
    "\n",
    "# Add y=x line\n",
    "ax[1].axline((plot_min, plot_min), (plot_max, plot_max), color='black', linestyle='dashed')\n",
    "\n",
    "# Set axis limits\n",
    "ax[1].set_xlim([plot_min, plot_max])\n",
    "ax[1].set_ylim([plot_min, plot_max])\n",
    "\n",
    "# Add labels\n",
    "ax[1].set_xlabel('Actual change in MBD')\n",
    "ax[1].set_ylabel('Predicted change in MBD')\n",
    "\n",
    "# Set log10 scales\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_yscale('log')\n",
    "\n",
    "# Add in a title and axes labels\n",
    "plt.suptitle('Predicted vs. actual validation microbusiness density change')\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(title='Forecast horizon month', loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs actual MBD values for validation set by the forecast horizon index\n",
    "\n",
    "# Set common axis limits\n",
    "data_pool = list(targets['validation'][2:].flatten()) + list(predictions['GRU_validation'][2:].flatten()) + list(predictions['control_validation'][2:].flatten())\n",
    "trimmed_data_pool = [i for i in data_pool if i > 0]\n",
    "\n",
    "plot_max = max(trimmed_data_pool)\n",
    "plot_min = min(trimmed_data_pool)\n",
    "\n",
    "# Make plots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Plot with linear axes\n",
    "ax[0].scatter(targets['validation'][2:], predictions['GRU_validation'][2:], s=params.plot_point_size, label='GRU model')\n",
    "ax[0].scatter(targets['validation'][2:], predictions['control_validation'][2:], s=params.plot_point_size, label='Naive control')\n",
    "\n",
    "# Add y=x line\n",
    "ax[0].axline((plot_min, plot_min), (plot_max, plot_max), color='black', linestyle='dashed')\n",
    "\n",
    "# Set axis limits\n",
    "ax[0].set_xlim([plot_min, plot_max])\n",
    "ax[0].set_ylim([plot_min, plot_max])\n",
    "\n",
    "# Add labels\n",
    "ax[0].set_xlabel('Actual change in MBD')\n",
    "ax[0].set_ylabel('Predicted change in MBD')\n",
    "\n",
    "# Plot again with log10 axes\n",
    "ax[1].scatter(targets['validation'][2:], predictions['GRU_validation'][2:], s=params.plot_point_size, label='GRU model')\n",
    "ax[1].scatter(targets['validation'][2:], predictions['control_validation'][2:], s=params.plot_point_size, label='Naive control')\n",
    "\n",
    "# Add y=x line\n",
    "ax[1].axline((plot_min, plot_min), (plot_max, plot_max), color='black', linestyle='dashed')\n",
    "\n",
    "# Set axis limits\n",
    "ax[1].set_xlim([plot_min, plot_max])\n",
    "ax[1].set_ylim([plot_min, plot_max])\n",
    "\n",
    "# Add labels\n",
    "ax[1].set_xlabel('Actual MBD')\n",
    "ax[1].set_ylabel('Predicted MBD')\n",
    "\n",
    "# Set log10 scales\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_yscale('log')\n",
    "\n",
    "# Add in a title and axes labels\n",
    "plt.suptitle('Predicted vs. actual validation microbusiness density change: public leaderboard forecast horizon')\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microbusiness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c89e0f329143aafc2740b6540b46c06e92791a1e818eb6a9ece1d952786ba476"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
