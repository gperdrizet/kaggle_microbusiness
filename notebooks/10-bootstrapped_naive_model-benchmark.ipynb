{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 5: Oneshot naive model structured bootstrap resampling\n",
    "Ok, so, I talked about the rationale and set-up for this at length in notebooks 08 & 09. Let's give it a test. Success criteria here is that our observed public leader score of ~1.09 for the naive 'carry-forward' model should not have a vanishingly small probability of coming from this dataset using this resampling procedure. If the SMAPE score distribution generated by this sampling procedure with the naive model is consistent with the observed public leaderboard score for the same model, we can declare victory and move on the better models and better data.\n",
    "1. [Abbreviations & definitions](#abbrevations_definitions)\n",
    "2. [Load & inspect](#load_inspect)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"abbreviations_definitions\"></a>\n",
    "### 1. Abbreviations & definitions\n",
    "+ MBD: microbusiness density\n",
    "+ MBC: microbusiness count\n",
    "+ OLS: ordinary least squares\n",
    "+ Model order: number of past timepoints used as input data for model training\n",
    "+ Origin (forecast origin): last known point in the input data\n",
    "+ Horizon (forecast horizon): number of future data points predicted by the model\n",
    "+ SMAPE: Symmetric mean absolute percentage error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"load_inspect\"></a>\n",
    "### 2. Load & inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.0 | packaged by conda-forge | (default, Nov 20 2021, 02:24:10) [GCC 9.4.0]\n",
      "\n",
      "Numpy 1.23.5\n",
      "Pandas 1.4.3\n"
     ]
    }
   ],
   "source": [
    "# Add parent directory to path to allow import of config.py\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import config as conf\n",
    "import functions.data_manipulation_functions as data_funcs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from statistics import NormalDist\n",
    "\n",
    "print(f'Python: {sys.version}')\n",
    "print()\n",
    "print(f'Numpy {np.__version__}')\n",
    "print(f'Pandas {pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timepoints shape: (31, 3135, 8, 5)\n",
      "\n",
      "Column types:\n",
      "\t<class 'numpy.float64'>\n",
      "\t<class 'numpy.float64'>\n",
      "\t<class 'numpy.float64'>\n",
      "\t<class 'numpy.float64'>\n",
      "\t<class 'numpy.float64'>\n",
      "\n",
      "Example block:\n",
      "[[1.0010000e+03 1.5646176e+18 3.0076818e+00 1.2490000e+03 0.0000000e+00]\n",
      " [1.0010000e+03 1.5672960e+18 2.8848701e+00 1.1980000e+03 1.0000000e+00]\n",
      " [1.0010000e+03 1.5698880e+18 3.0558431e+00 1.2690000e+03 2.0000000e+00]\n",
      " [1.0010000e+03 1.5725664e+18 2.9932332e+00 1.2430000e+03 3.0000000e+00]\n",
      " [1.0010000e+03 1.5751584e+18 2.9932332e+00 1.2430000e+03 4.0000000e+00]\n",
      " [1.0010000e+03 1.5778368e+18 2.9690900e+00 1.2420000e+03 5.0000000e+00]\n",
      " [1.0010000e+03 1.5805152e+18 2.9093256e+00 1.2170000e+03 6.0000000e+00]\n",
      " [1.0010000e+03 1.5830208e+18 2.9332314e+00 1.2270000e+03 7.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Load parsed data\n",
    "block_size = 8\n",
    "\n",
    "output_file = f'{conf.DATA_PATH}/parsed_data/structured_bootstrap_blocksize{block_size}.npy'\n",
    "timepoints = np.load(output_file)\n",
    "\n",
    "print(f'Timepoints shape: {timepoints.shape}')\n",
    "print()\n",
    "print('Column types:')\n",
    "\n",
    "for column in timepoints[0,0,0,0:]:\n",
    "    print(f'\\t{type(column)}')\n",
    "\n",
    "print()\n",
    "print(f'Example block:\\n{timepoints[0,0,0:,]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK this, numpy array is structured as follows:\n",
    "+ **First dimension**: timepoints: left-edge anchored with respect to the timeseries. Each element contains the timeseries blocks for each county.\n",
    "+ **Second dimension**: counties: each element is the timeseries block for that county.\n",
    "+ **Third dimension**: rows: timeseries for block, starting from the left edge of the timepoint and running forward by bin_num timepoints.\n",
    "+ **Fourth dimension**: columns: *cfips, first_day_of_month, microbusiness_density, active*, all floats.\n",
    "\n",
    "Let's start by defining some helper functions so that we can easily score multiple samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 3\n",
    "sample_size = 100\n",
    "model_order = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model order is not a parameter of the naive model, since we are just going to carry forward the last MBD value. But, I want to build it in for the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_parsed_data(timepoints, sample_size):\n",
    "    '''Generates a random sample of sample_size from a random timepoint'''\n",
    "\n",
    "    # Initialize random seed to make sure that output is differently random each call\n",
    "    np.random.seed()\n",
    "\n",
    "    # Pick random timepoint\n",
    "    random_timepoint_index = np.random.choice(timepoints.shape[0], 1)\n",
    "    timepoint = timepoints[random_timepoint_index][0]\n",
    "\n",
    "    #print(f'Timepoint shape: {timepoint.shape}')\n",
    "\n",
    "    # Pick n unique random county indexes to include in the sample\n",
    "    random_county_indices = np.random.choice(timepoint.shape[0], sample_size, replace=False)\n",
    "\n",
    "    # Use random indices to extract sample from timepoint\n",
    "    sample = timepoint[random_county_indices]\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_point_smape(actual, forecast):\n",
    "\n",
    "    # If SMAPE denominator is zero set SMAPE to zero\n",
    "    if actual == 0 and forecast == 0:\n",
    "        return 0\n",
    "\n",
    "    # Calculate smape for forecast\n",
    "    smape = abs(forecast - actual) / ((abs(actual) + abs(forecast)) / 2)\n",
    "    \n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_model_smape_score(sample, model_order):\n",
    "    '''Takes a sample of blocks and gets smape values for each'''\n",
    "\n",
    "    # Holder for SMAPE values\n",
    "    smape_values = []\n",
    "\n",
    "    for block_num in range(sample.shape[0]):\n",
    "\n",
    "        # Get the forecasted value - last value in the model order (input) range\n",
    "        forecast_value = sample[block_num, (model_order - 1), 2]\n",
    "\n",
    "        # Get the true value\n",
    "        actual_value = sample[block_num, model_order, 2]\n",
    "\n",
    "        # Get and collect SMAPE value for this forecast\n",
    "        smape_value = two_point_smape(actual_value, forecast_value)\n",
    "        smape_values.append(smape_value)\n",
    "\n",
    "        #print(f'Forecast: {forecast_value}, actual value: {actual_value}, SMAPE score: {smape_value}')\n",
    "\n",
    "    smape_score = (100/len(smape_values)) * sum(smape_values)\n",
    "\n",
    "    return smape_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_smape_score(timepoints, num_samples, sample_size, model_order):\n",
    "\n",
    "    smape_scores = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        sample = sample_parsed_data(timepoints, sample_size)\n",
    "        smape_score = naive_model_smape_score(sample, model_order)\n",
    "\n",
    "        smape_scores.append(smape_score)\n",
    "\n",
    "    return smape_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_scores = bootstrap_smape_score(timepoints, num_samples, sample_size, model_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1260596670000735, 1.3034519430519285, 1.6618666446624843]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microbusiness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c89e0f329143aafc2740b6540b46c06e92791a1e818eb6a9ece1d952786ba476"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
