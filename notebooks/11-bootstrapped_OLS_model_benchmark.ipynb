{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 6: OLS model structured bootstrap resampling\n",
    "Now that we have a resampling strategy that gives us at least some confidence that our internal benchmarking scores could be reflective of what will happened when we submit to the public leaderboard. Let's start working on the model. The first thing I want to try is another shot at the OLS model. Firstly, to see if we can make any clever improvements. But, mostly to generalize the functions written to resample, forecast and score the naive model.\n",
    "1. [Abbreviations & definitions](#abbrevations_definitions)\n",
    "2. [Load & inspect](#load_inspect)\n",
    "3. [Helper functions](#helper_functions)\n",
    "\n",
    "<a name=\"abbreviations_definitions\"></a>\n",
    "### 1. Abbreviations & definitions\n",
    "+ MBD: microbusiness density\n",
    "+ MBC: microbusiness count\n",
    "+ OLS: ordinary least squares\n",
    "+ Model order: number of past timepoints used as input data for model training\n",
    "+ Origin (forecast origin): last known point in the input data\n",
    "+ Horizon (forecast horizon): number of future data points predicted by the model\n",
    "+ SMAPE: Symmetric mean absolute percentage error\n",
    "\n",
    "<a name=\"load_inspect\"></a>\n",
    "### 2. Load & inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.0 | packaged by conda-forge | (default, Nov 20 2021, 02:24:10) [GCC 9.4.0]\n",
      "\n",
      "Numpy 1.23.5\n",
      "Pandas 1.4.3\n"
     ]
    }
   ],
   "source": [
    "# Add parent directory to path to allow import of config.py\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import config as conf\n",
    "import functions.data_manipulation_functions as data_funcs\n",
    "\n",
    "#import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "#from statsmodels.tsa.arima.model import ARIMA\n",
    "#import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from statistics import NormalDist\n",
    "from scipy import stats\n",
    "\n",
    "print(f'Python: {sys.version}')\n",
    "print()\n",
    "print(f'Numpy {np.__version__}')\n",
    "print(f'Pandas {pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timepoints shape: (4, 3135, 33, 6)\n",
      "\n",
      "Column types:\n",
      "\t<class 'numpy.float64'>\n",
      "\t<class 'numpy.float64'>\n",
      "\t<class 'numpy.float64'>\n",
      "\t<class 'numpy.float64'>\n",
      "\t<class 'numpy.float64'>\n",
      "\t<class 'numpy.float64'>\n",
      "\n",
      "Example block:\n",
      "[[ 1.0010000e+03  1.5672960e+18  2.8848701e+00  1.1980000e+03\n",
      "   1.0000000e+00 -1.2281170e-01]\n",
      " [ 1.0010000e+03  1.5698880e+18  3.0558431e+00  1.2690000e+03\n",
      "   2.0000000e+00  1.7097300e-01]\n",
      " [ 1.0010000e+03  1.5725664e+18  2.9932332e+00  1.2430000e+03\n",
      "   3.0000000e+00 -6.2609900e-02]\n",
      " [ 1.0010000e+03  1.5751584e+18  2.9932332e+00  1.2430000e+03\n",
      "   4.0000000e+00  0.0000000e+00]\n",
      " [ 1.0010000e+03  1.5778368e+18  2.9690900e+00  1.2420000e+03\n",
      "   5.0000000e+00 -2.4143200e-02]\n",
      " [ 1.0010000e+03  1.5805152e+18  2.9093256e+00  1.2170000e+03\n",
      "   6.0000000e+00 -5.9764400e-02]\n",
      " [ 1.0010000e+03  1.5830208e+18  2.9332314e+00  1.2270000e+03\n",
      "   7.0000000e+00  2.3905800e-02]\n",
      " [ 1.0010000e+03  1.5856992e+18  3.0001674e+00  1.2550000e+03\n",
      "   8.0000000e+00  6.6936000e-02]\n",
      " [ 1.0010000e+03  1.5882912e+18  3.0049484e+00  1.2570000e+03\n",
      "   9.0000000e+00  4.7810000e-03]\n",
      " [ 1.0010000e+03  1.5909696e+18  3.0192919e+00  1.2630000e+03\n",
      "   1.0000000e+01  1.4343500e-02]\n",
      " [ 1.0010000e+03  1.5935616e+18  3.0838373e+00  1.2900000e+03\n",
      "   1.1000000e+01  6.4545400e-02]\n",
      " [ 1.0010000e+03  1.5962400e+18  3.1746790e+00  1.3280000e+03\n",
      "   1.2000000e+01  9.0841700e-02]\n",
      " [ 1.0010000e+03  1.5989184e+18  3.2057564e+00  1.3410000e+03\n",
      "   1.3000000e+01  3.1077400e-02]\n",
      " [ 1.0010000e+03  1.6015104e+18  3.1938035e+00  1.3360000e+03\n",
      "   1.4000000e+01 -1.1952900e-02]\n",
      " [ 1.0010000e+03  1.6041888e+18  3.0384164e+00  1.2710000e+03\n",
      "   1.5000000e+01 -1.5538710e-01]\n",
      " [ 1.0010000e+03  1.6067808e+18  3.0025580e+00  1.2560000e+03\n",
      "   1.6000000e+01 -3.5858400e-02]\n",
      " [ 1.0010000e+03  1.6094592e+18  2.9472437e+00  1.2430000e+03\n",
      "   1.7000000e+01 -5.5314300e-02]\n",
      " [ 1.0010000e+03  1.6121376e+18  3.1061056e+00  1.3100000e+03\n",
      "   1.8000000e+01  1.5886190e-01]\n",
      " [ 1.0010000e+03  1.6145568e+18  3.1440427e+00  1.3260000e+03\n",
      "   1.9000000e+01  3.7937100e-02]\n",
      " [ 1.0010000e+03  1.6172352e+18  3.2246592e+00  1.3600000e+03\n",
      "   2.0000000e+01  8.0616500e-02]\n",
      " [ 1.0010000e+03  1.6198272e+18  3.2270303e+00  1.3610000e+03\n",
      "   2.1000000e+01  2.3711000e-03]\n",
      " [ 1.0010000e+03  1.6225056e+18  3.2222881e+00  1.3590000e+03\n",
      "   2.2000000e+01 -4.7422000e-03]\n",
      " [ 1.0010000e+03  1.6250976e+18  3.2104328e+00  1.3540000e+03\n",
      "   2.3000000e+01 -1.1855300e-02]\n",
      " [ 1.0010000e+03  1.6277760e+18  3.2199171e+00  1.3580000e+03\n",
      "   2.4000000e+01  9.4843000e-03]\n",
      " [ 1.0010000e+03  1.6304544e+18  3.1867220e+00  1.3440000e+03\n",
      "   2.5000000e+01 -3.3195100e-02]\n",
      " [ 1.0010000e+03  1.6330464e+18  3.2033195e+00  1.3510000e+03\n",
      "   2.6000000e+01  1.6597500e-02]\n",
      " [ 1.0010000e+03  1.6357248e+18  3.2009485e+00  1.3500000e+03\n",
      "   2.7000000e+01 -2.3710000e-03]\n",
      " [ 1.0010000e+03  1.6383168e+18  3.2863071e+00  1.3860000e+03\n",
      "   2.8000000e+01  8.5358600e-02]\n",
      " [ 1.0010000e+03  1.6409952e+18  3.2967808e+00  1.4010000e+03\n",
      "   2.9000000e+01  1.0473700e-02]\n",
      " [ 1.0010000e+03  1.6436736e+18  3.3344314e+00  1.4170000e+03\n",
      "   3.0000000e+01  3.7650600e-02]\n",
      " [ 1.0010000e+03  1.6460928e+18  3.3367846e+00  1.4180000e+03\n",
      "   3.1000000e+01  2.3532000e-03]\n",
      " [ 1.0010000e+03  1.6487712e+18  3.3720820e+00  1.4330000e+03\n",
      "   3.2000000e+01  3.5297400e-02]\n",
      " [ 1.0010000e+03  1.6513632e+18  3.3132529e+00  1.4080000e+03\n",
      "   3.3000000e+01 -5.8829100e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Load parsed data\n",
    "block_size = 33\n",
    "\n",
    "output_file = f'{conf.DATA_PATH}/parsed_data/structured_bootstrap_blocksize{block_size}.npy'\n",
    "timepoints = np.load(output_file)\n",
    "\n",
    "print(f'Timepoints shape: {timepoints.shape}')\n",
    "print()\n",
    "print('Column types:')\n",
    "\n",
    "for column in timepoints[0,0,0,0:]:\n",
    "    print(f'\\t{type(column)}')\n",
    "\n",
    "print()\n",
    "print(f'Example block:\\n{timepoints[0,0,0:,]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"helper_functions\"></a>\n",
    "### 3. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_point_smape(actual, forecast):\n",
    "    '''Takes two datapoints and returns the SMAPE value for the pair'''\n",
    "\n",
    "    # If SMAPE denominator is zero set SMAPE to zero\n",
    "    if actual == 0 and forecast == 0:\n",
    "        return 0\n",
    "\n",
    "    # Calculate smape for forecast\n",
    "    smape = abs(forecast - actual) / ((abs(actual) + abs(forecast)) / 2)\n",
    "    \n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_parsed_data(timepoints, sample_size):\n",
    "    '''Generates a random sample of sample_size from a random timepoint'''\n",
    "\n",
    "    # Initialize random seed to make sure that output is differently random each call\n",
    "    np.random.seed()\n",
    "\n",
    "    # Pick random timepoint\n",
    "    random_timepoint_index = np.random.choice(timepoints.shape[0], 1)\n",
    "    timepoint = timepoints[random_timepoint_index][0]\n",
    "\n",
    "    if sample_size == 'all':\n",
    "        return timepoint\n",
    "\n",
    "    # Pick n unique random county indexes to include in the sample\n",
    "    random_county_indices = np.random.choice(timepoint.shape[0], sample_size, replace=False)\n",
    "\n",
    "    # Use random indices to extract sample from timepoint\n",
    "    sample = timepoint[random_county_indices]\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_forecasts(block, model_types, model_order):\n",
    "    '''Uses specified model type and model order to forecast\n",
    "    within block, one timepoint into the future. Also returns\n",
    "    naive, 'carry-forward' prediction for the same datapoint \n",
    "    for comparison'''\n",
    "\n",
    "    # Holder for SMAPE values\n",
    "    block_predictions = {\n",
    "        'model_type': [],\n",
    "        'model_order': [],\n",
    "        'MBD_predictions': [],\n",
    "        'detrended_MBD_predictions': [],\n",
    "        'MBD_inputs': [],\n",
    "        'detrended_MBD_inputs': []\n",
    "    }\n",
    "\n",
    "    # Get prediction for naive control. Note: these are indexes\n",
    "    # so model_order gets the model_order th element (zero anchored)\n",
    "    block_predictions['model_type'].append('control')\n",
    "    block_predictions['model_order'].append(model_order)\n",
    "    block_predictions['MBD_predictions'].append(block[(model_order - 1), 2])\n",
    "    block_predictions['detrended_MBD_predictions'].append(block[(model_order - 1), 5] + block[model_order, 2])\n",
    "\n",
    "    # X input is model_order sequential integers\n",
    "    x_input = list(range(model_order))\n",
    "\n",
    "    # Y input is MBD values starting from the left\n",
    "    # edge of the block, up to the model order. Note: this\n",
    "    # is a slice so, the right edge is exclusive \n",
    "    y_input = list(block[:model_order, 2])\n",
    "    detrended_y_input = list(block[:model_order, 5])\n",
    "\n",
    "    block_predictions['MBD_inputs'].append(y_input)\n",
    "    block_predictions['detrended_MBD_inputs'].append(detrended_y_input)\n",
    "\n",
    "    # Forecast X input is sequential integers starting\n",
    "    # after the end of the X input. Note: we are only interested\n",
    "    # in the first prediction here, but some statsmodels estimators\n",
    "    # expect the same dim during forecast as they were fitted \n",
    "    forecast_x = list(range(model_order, (model_order * 2)))\n",
    "\n",
    "    for model_type in model_types:\n",
    "\n",
    "        if model_type == 'OLS':\n",
    "\n",
    "            # Add model type to results\n",
    "            block_predictions['model_type'].append(model_type)\n",
    "\n",
    "            # Add model order to results\n",
    "            block_predictions['model_order'].append(model_order)\n",
    "\n",
    "            block_predictions['MBD_inputs'].append(y_input)\n",
    "            block_predictions['detrended_MBD_inputs'].append(detrended_y_input)\n",
    "\n",
    "            # Fit and predict raw data\n",
    "            model = sm.OLS(y_input, sm.add_constant(x_input)).fit()\n",
    "            prediction = model.predict(sm.add_constant(forecast_x))\n",
    "\n",
    "            # Collect forecast\n",
    "            block_predictions['MBD_predictions'].append(prediction[0])\n",
    "\n",
    "            # Fit and predict detrended data\n",
    "            model = sm.OLS(detrended_y_input, sm.add_constant(x_input)).fit()\n",
    "            prediction = model.predict(sm.add_constant(forecast_x))\n",
    "\n",
    "            # Collect forecast\n",
    "            block_predictions['detrended_MBD_predictions'].append(prediction[0] + block[model_order, 2])\n",
    "\n",
    "        if model_type == 'TS':\n",
    "\n",
    "            # Add model type to results\n",
    "            block_predictions['model_type'].append(model_type)\n",
    "\n",
    "            # Add model order to results\n",
    "            block_predictions['model_order'].append(model_order)\n",
    "\n",
    "            block_predictions['MBD_inputs'].append(y_input)\n",
    "            block_predictions['detrended_MBD_inputs'].append(detrended_y_input)\n",
    "\n",
    "            # Fit Theil-Sen to raw data\n",
    "            ts = stats.theilslopes(y_input, x_input)\n",
    "\n",
    "            # Calculate forecast from Theil-Sen slope and intercept, add to results\n",
    "            block_predictions['MBD_predictions'].append(ts[1] + ts[0] * forecast_x[0])\n",
    "\n",
    "            # Fit Theil-Sen to detrended data\n",
    "            ts = stats.theilslopes(detrended_y_input, x_input)\n",
    "\n",
    "            # Calculate forecast from Theil-Sen slope and intercept, add to results\n",
    "            block_predictions['detrended_MBD_predictions'].append((ts[1] + ts[0] * forecast_x[0]) + block[model_order, 2])\n",
    "\n",
    "        if model_type == 'Seigel':\n",
    "\n",
    "            # Add model type to results\n",
    "            block_predictions['model_type'].append(model_type)\n",
    "\n",
    "            # Add model order to results\n",
    "            block_predictions['model_order'].append(model_order)\n",
    "\n",
    "            block_predictions['MBD_inputs'].append(y_input)\n",
    "            block_predictions['detrended_MBD_inputs'].append(detrended_y_input)\n",
    "\n",
    "            # Fit Seigel to raw data\n",
    "            ss = stats.siegelslopes(y_input, x_input)\n",
    "\n",
    "            # Calculate forecast from Seigel slope and intercept, add to results\n",
    "            block_predictions['MBD_predictions'].append(ss[1] + ss[0] * forecast_x[0])\n",
    "\n",
    "            # Fit Theil-Sen to detrended data\n",
    "            ss = stats.siegelslopes(detrended_y_input, x_input)\n",
    "\n",
    "            # Calculate forecast from Seigel slope and intercept, add to results\n",
    "            block_predictions['detrended_MBD_predictions'].append((ss[1] + ss[0] * forecast_x[0]) + block[model_order, 2])\n",
    "\n",
    "        if model_type == 'ARIMA':\n",
    "\n",
    "            # Add model type to results\n",
    "            block_predictions['model_type'].append(model_type)\n",
    "\n",
    "            # Add model order to results\n",
    "            block_predictions['model_order'].append(model_order)\n",
    "\n",
    "            block_predictions['MBD_inputs'].append(y_input)\n",
    "            block_predictions['detrended_MBD_inputs'].append(detrended_y_input)\n",
    "\n",
    "            # Fit ARIMA to raw data\n",
    "            arima = sm.tsa.arima.ARIMA(y_input, order=(model_order,2,1)).fit()\n",
    "\n",
    "            # Calculate forecast from ARIMA slope and intercept, add to results\n",
    "            block_predictions['MBD_predictions'].append(arima.forecast()[0])\n",
    "\n",
    "            # Fit ARIMA to detrended data\n",
    "            arima = sm.tsa.arima.ARIMA(detrended_y_input, order=(model_order,2,1)).fit()\n",
    "\n",
    "            # Calculate forecast from ARIMA slope and intercept, add to results\n",
    "            block_predictions['detrended_MBD_predictions'].append(arima.forecast()[0] + block[model_order, 2])\n",
    "\n",
    "    #print(f'Block predictions: {block_predictions}')    \n",
    "\n",
    "    return block_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_score_models(sample, model_types, model_order):\n",
    "    '''Takes a sample of blocks, makes forecast for each \n",
    "    and collects resulting SMAPE values'''\n",
    "\n",
    "    # Holder for SMAPE values\n",
    "    block_data = {\n",
    "        'model_type': [],\n",
    "        'model_order': [],\n",
    "        'SMAPE_values': [],\n",
    "        'detrended_SMAPE_values': [],\n",
    "        'MBD_predictions': [],\n",
    "        'detrended_MBD_predictions': [],\n",
    "        'MBD_inputs': [],\n",
    "        'detrended_MBD_inputs': [],\n",
    "        'MBD_actual': []\n",
    "    }\n",
    "\n",
    "    for block_num in range(sample.shape[0]):\n",
    "\n",
    "        # Get the forecasted value(s)\n",
    "        block_predictions = make_forecasts(sample[block_num], model_types, model_order)\n",
    "\n",
    "        # Collect predictions, input data and model info.\n",
    "        for key, value in block_predictions.items():\n",
    "            block_data[key].extend(value)\n",
    "\n",
    "        # # Add model types and orders from the block results to the SMAPE values holder\n",
    "        # block_smape_values['model_type'].extend(block_predictions['model_type'])\n",
    "        # block_smape_values['model_order'].extend(block_predictions['model_order'])\n",
    "\n",
    "        # # Add data\n",
    "        # block_smape_values['MBD_predictions'].extend(block_predictions['MBD_predictions'])\n",
    "        # block_smape_values['detrended_MBD_predictions'].extend(block_predictions['detrended_MBD_predictions'])\n",
    "        # block_smape_values['MBD_inputs'].extend(block_predictions['MBD_inputs'])\n",
    "        # block_smape_values['detrended_MBD_inputs'].extend(block_predictions['detrended_MBD_inputs'])\n",
    "\n",
    "        # Get the true value and add to data\n",
    "        actual_value = sample[block_num, model_order, 2]\n",
    "\n",
    "        # Get and collect SMAPE value for models\n",
    "        for value in block_predictions['MBD_predictions']:\n",
    "\n",
    "            smape_value = two_point_smape(actual_value, value)\n",
    "            block_data['SMAPE_values'].append(smape_value)\n",
    "            block_data['MBD_actual'].append(actual_value)\n",
    "\n",
    "        # Get and collect SMAPE value for models\n",
    "        for value in block_predictions['detrended_MBD_predictions']:\n",
    "\n",
    "            smape_value = two_point_smape(actual_value, value)\n",
    "            block_data['detrended_SMAPE_values'].append(smape_value)\n",
    "            #block_data['MBD_actual'].append(actual_value)\n",
    "\n",
    "    return block_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_smape_scores(timepoints, sample_num, sample_size, model_order, model_types):\n",
    "\n",
    "    # Holder for sample results\n",
    "    sample_data = {\n",
    "        'sample': [],\n",
    "        'model_type': [],\n",
    "        'model_order': [],\n",
    "        'SMAPE_values': [],\n",
    "        'detrended_SMAPE_values': [],\n",
    "        'MBD_predictions': [],\n",
    "        'detrended_MBD_predictions': [],\n",
    "        'MBD_inputs': [],\n",
    "        'detrended_MBD_inputs': [],\n",
    "        'MBD_actual': []\n",
    "    }\n",
    "\n",
    "    # Generate sample of random blocks from random timepoint\n",
    "    sample = sample_parsed_data(timepoints, sample_size)\n",
    "\n",
    "    # Do forecast and aggregate score across each block in sample\n",
    "    result = smape_score_models(sample, model_types, model_order)\n",
    "\n",
    "    for key, value in result.items():\n",
    "        sample_data[key].extend(value)\n",
    "\n",
    "    sample_data['sample'].extend([sample_num] * len(result['model_type']))\n",
    "\n",
    "    return sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_bootstrapped_smape(\n",
    "    timepoints, \n",
    "    sample_num, \n",
    "    sample_size, \n",
    "    model_orders, \n",
    "    model_types\n",
    "):\n",
    "    \n",
    "    # Holder for sample results\n",
    "    data = {\n",
    "        'sample': [],\n",
    "        'model_type': [],\n",
    "        'model_order': [],\n",
    "        'SMAPE_values': [],\n",
    "        'detrended_SMAPE_values': [],\n",
    "        'MBD_predictions': [],\n",
    "        'detrended_MBD_predictions': [],\n",
    "        'MBD_inputs': [],\n",
    "        'detrended_MBD_inputs': [],\n",
    "        'MBD_actual': []\n",
    "    }\n",
    "\n",
    "    # Loop on model orders\n",
    "    for model_order in model_orders:\n",
    "        result = bootstrap_smape_scores(            \n",
    "            timepoints, \n",
    "            sample_num, \n",
    "            sample_size, \n",
    "            model_order, \n",
    "            model_types\n",
    "        )\n",
    "\n",
    "        for key, value in result.items():\n",
    "            data[key].extend(value)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processes for 18 CPUs (available - 2)\n"
     ]
    }
   ],
   "source": [
    "# Ignore warnings from ARIMA parameter optimization\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "num_samples = 18\n",
    "sample_size = 100\n",
    "model_orders = [2,4,6,8,10,12,14,16]\n",
    "model_types = ['OLS', 'TS', 'Seigel', 'ARIMA']\n",
    "\n",
    "# Fire up the pool\n",
    "pool, result_objects = data_funcs.start_multiprocessing_pool()\n",
    "\n",
    "for sample_num in range(sample_size):\n",
    "\n",
    "    result = pool.apply_async(parallel_bootstrapped_smape,\n",
    "        args = (\n",
    "            timepoints, \n",
    "            sample_num, \n",
    "            sample_size, \n",
    "            model_orders, \n",
    "            model_types\n",
    "        )\n",
    "    )\n",
    "\n",
    "    result_objects.append(result)\n",
    "\n",
    "data = data_funcs.cleanup_bootstrapping_multiprocessing_pool(pool, result_objects)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in data.items():\n",
    "    print(f'{key}: {len(value)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_scores_df = data_df.groupby(['sample', 'model_type', 'model_order'])[['SMAPE_values', 'detrended_SMAPE_values']].mean().mul(100)\n",
    "smape_scores_df.rename(inplace=True, columns={'SMAPE_values': 'SMAPE_score', 'detrended_SMAPE_values': 'detrended_SMAPE_score'})\n",
    "smape_scores_df.reset_index(inplace=True, drop=False)\n",
    "smape_scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(\n",
    "    data=smape_scores_df, \n",
    "    x='model_type',\n",
    "    y='SMAPE_score',\n",
    "    hue='model_order'\n",
    ")\n",
    "\n",
    "titles = ax.set(\n",
    "    xlabel='Model', \n",
    "    ylabel='SMAPE score', \n",
    "    title='Bootstrapped SMAPE score distribution by model type'\n",
    ")\n",
    "\n",
    "# xticks = ax.set_xticks(ax.get_xticks()) # type: ignore\n",
    "# xticklabels = ax.set_xticklabels(ax.get_xticklabels(), rotation=45, fontsize=12) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(\n",
    "    data=smape_scores_df, \n",
    "    x='model_type',\n",
    "    y='detrended_SMAPE_score',\n",
    "    hue='model_order'\n",
    ")\n",
    "\n",
    "titles = ax.set(\n",
    "    xlabel='SMAPE score', \n",
    "    ylabel='Density', \n",
    "    title='Bootstrapped detrended SMAPE score distribution by model type'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12,4))\n",
    "\n",
    "ax[0].scatter(\n",
    "    data_df[(data_df['model_type'] == 'control') & (data_df['model_order'] == 32)]['SMAPE_values'],\n",
    "    data_df[(data_df['model_type'] == 'OLS') & (data_df['model_order'] == 32)]['SMAPE_values']\n",
    ")\n",
    "ax[0].set_xlabel('naive SMAPE score')\n",
    "ax[0].set_ylabel('OLS SMAPE score')\n",
    "\n",
    "ax[1].scatter(\n",
    "    data_df[(data_df['model_type'] == 'control') & (data_df['model_order'] == 32)]['SMAPE_values'],\n",
    "    data_df[(data_df['model_type'] == 'TS') & (data_df['model_order'] == 32)]['SMAPE_values']\n",
    ")\n",
    "ax[1].set_xlabel('naive SMAPE score')\n",
    "ax[1].set_ylabel('TS SMAPE score')\n",
    "\n",
    "ax[2].scatter(\n",
    "    data_df[(data_df['model_type'] == 'control') & (data_df['model_order'] == 32)]['SMAPE_values'],\n",
    "    data_df[(data_df['model_type'] == 'Seigel') & (data_df['model_order'] == 32)]['SMAPE_values']\n",
    ")\n",
    "ax[2].set_xlabel('naive SMAPE score')\n",
    "ax[2].set_ylabel('Seigel SMAPE score')\n",
    "\n",
    "plt.suptitle('Regression models vs naive control')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12,4))\n",
    "\n",
    "ax[0].scatter(\n",
    "    data_df[(data_df['model_type'] == 'control') & (data_df['model_order'] == 32)]['detrended_SMAPE_values'],\n",
    "    data_df[(data_df['model_type'] == 'OLS') & (data_df['model_order'] == 32)]['detrended_SMAPE_values']\n",
    ")\n",
    "ax[0].set_xlabel('naive SMAPE value')\n",
    "ax[0].set_ylabel('OLS SMAPE value')\n",
    "\n",
    "ax[1].scatter(\n",
    "    data_df[(data_df['model_type'] == 'control') & (data_df['model_order'] == 32)]['detrended_SMAPE_values'],\n",
    "    data_df[(data_df['model_type'] == 'TS') & (data_df['model_order'] == 32)]['detrended_SMAPE_values']\n",
    ")\n",
    "ax[1].set_xlabel('naive SMAPE value')\n",
    "ax[1].set_ylabel('TS SMAPE value')\n",
    "\n",
    "ax[2].scatter(\n",
    "    data_df[(data_df['model_type'] == 'control') & (data_df['model_order'] == 32)]['detrended_SMAPE_values'],\n",
    "    data_df[(data_df['model_type'] == 'Seigel') & (data_df['model_order'] == 32)]['detrended_SMAPE_values']\n",
    ")\n",
    "ax[2].set_xlabel('naive SMAPE score')\n",
    "ax[2].set_ylabel('Seigel SMAPE score')\n",
    "\n",
    "plt.suptitle('Regression models vs naive control, detrended data')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oooo, this plot is tantalizing - look at the blob in the upper left of both plots. We clearly have cases where the naive model does terribly and the regression model does better. If we could somehow pick the right model on the fly without having to see the actual forecast value we could improve this a lot. Part of me wants to spend some time on it, part of me thinks it's time to move on to ARIMA family models and GRUs/LSTMs...\n",
    "\n",
    "The decision of what model to use would have to be made on the basis of descriptive stats on the input data or diagnostic data about the regression fit. I think the first thing to do would be to recover the samples that are producing the blob. Not sure that it's worth the time and effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "\n",
    "ax.scatter(\n",
    "    data_df[(data_df['model_type'] == 'OLS') & (data_df['model_order'] == 32)]['SMAPE_values'],\n",
    "    data_df[(data_df['model_type'] == 'TS') & (data_df['model_order'] == 32)]['SMAPE_values']\n",
    ")\n",
    "\n",
    "ax.set_xlabel('OLS SMAPE value')\n",
    "ax.set_ylabel('TS SMAPE value')\n",
    "\n",
    "plt.suptitle('Theil-Sen estimator vs OLS regression')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microbusiness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c89e0f329143aafc2740b6540b46c06e92791a1e818eb6a9ece1d952786ba476"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
