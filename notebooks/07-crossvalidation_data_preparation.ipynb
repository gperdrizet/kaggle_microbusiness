{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation data preparation\n",
    "Lots of choices to make here. One thing which stands out is the small number of timepoints. I think this is a major issue. The other way to think about the problem is to consider each county as an individual data point with 39 measurements. Then break the time series for each county into blocks and consider each on a unique data instance. The final model will be trained to make predictions for any of the counties, at any point in time, one at a time. This might be a tall order given the variation between counties, but it gives us a lot more datapoints to work with: 39 timepoints x 3,135 counties = 122,265 datapoints. Hopefully, exogenous data sources will help with the between county variability somewhat - e.g. demographic, economic or geographic data.\n",
    "\n",
    "The plan is to use a rolling origin strategy with a forecast horizon of four months and a fixed model order. We should set things up so that the model order is a optimizable parameter, but let's pick four to start. So, we will predict four future values based on four past values across the time series for each county. This does raise a concern about data leakage, as data from the first forecast will be used as input to the next block, but I think it's necessary to maximize the use of the small dataset. A few things we can do to mitigate: \n",
    "1. Keep a real out-of sample test set.\n",
    "2. Do not perform any feature engineering, smoothing or normalization on the whole dataset before the split.\n",
    "3. Randomize, randomize, randomize.\n",
    "\n",
    "Ok, enough ramble - let's get started.\n",
    "\n",
    "1. [Abbreviations & definitions](#abbrevations_definitions)\n",
    "2. [Load & inspect](#load_inspect)\n",
    "3. [Parse input/forecast blocks](#parse)\n",
    "4. [Sanity check](#sanity_check)\n",
    "5. [Write to disk](#write_to_disk)\n",
    "6. [TODO](#TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.0 | packaged by conda-forge | (default, Nov 20 2021, 02:24:10) [GCC 9.4.0]\n",
      "\n",
      "NumPy: 1.23.5\n",
      "Pandas: 1.4.3\n"
     ]
    }
   ],
   "source": [
    "# Add parent directory to path to allow import of config.py\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import config as conf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(f'Python: {sys.version}')\n",
    "print()\n",
    "print(f'NumPy: {np.__version__}')\n",
    "print(f'Pandas: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"abbreviations_definitions\"></a>\n",
    "### 1. Abbreviations & definitions\n",
    "+ MBD: microbusiness density\n",
    "+ MBC: microbusiness count\n",
    "+ OLS: ordinary least squares\n",
    "+ Model order: number of past timepoints used as input data for model training\n",
    "+ Origin (forecast origin): last known point in the input data\n",
    "+ Horizon (forecast horizon): number of future data points predicted by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_model_order = 4\n",
    "max_forecast_horizon = 4\n",
    "\n",
    "# Note: issue here with using numpy ndarray if \n",
    "# max_model_order != max_forecast_horizon, makes ragged array..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"load_inspect\"></a>\n",
    "### 2. Load & inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>cfips</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>microbusiness_density</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_2019-08-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>3.007682</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001_2019-09-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2.884870</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001_2019-10-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.055843</td>\n",
       "      <td>1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001_2019-11-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2.993233</td>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001_2019-12-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2.993233</td>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  cfips          county    state first_day_of_month  \\\n",
       "0  1001_2019-08-01   1001  Autauga County  Alabama         2019-08-01   \n",
       "1  1001_2019-09-01   1001  Autauga County  Alabama         2019-09-01   \n",
       "2  1001_2019-10-01   1001  Autauga County  Alabama         2019-10-01   \n",
       "3  1001_2019-11-01   1001  Autauga County  Alabama         2019-11-01   \n",
       "4  1001_2019-12-01   1001  Autauga County  Alabama         2019-12-01   \n",
       "\n",
       "   microbusiness_density  active  \n",
       "0               3.007682    1249  \n",
       "1               2.884870    1198  \n",
       "2               3.055843    1269  \n",
       "3               2.993233    1243  \n",
       "4               2.993233    1243  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load up training file, set dtype for first day of month\n",
    "training_df = pd.read_csv(f'{conf.KAGGLE_DATA_PATH}/train.csv.zip', compression='zip')\n",
    "training_df['first_day_of_month'] =  pd.to_datetime(training_df['first_day_of_month'])\n",
    "\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122265 entries, 0 to 122264\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   row_id                 122265 non-null  object        \n",
      " 1   cfips                  122265 non-null  int64         \n",
      " 2   county                 122265 non-null  object        \n",
      " 3   state                  122265 non-null  object        \n",
      " 4   first_day_of_month     122265 non-null  datetime64[ns]\n",
      " 5   microbusiness_density  122265 non-null  float64       \n",
      " 6   active                 122265 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(3)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "training_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, this code won't have to run many times - basically once for each model order we want to test, so it's ok if it's a little inefficient. It's more important that we nail this down in a way that is flexible and transparent. First step will be to scan across each counties timecourse and generate input and forecast block pairs.\n",
    "\n",
    "Let's start by getting a list of unique county cfips id numbers to loop on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"parse\"></a>\n",
    "### 3. Parse input/forecast blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num counties: 3135\n",
      "[1001, 1003, 1005, 1007, 1009, 1011, 1013, 1015, 1017, 1019]\n"
     ]
    }
   ],
   "source": [
    "# Get list of unique cfips\n",
    "cfips_list = training_df['cfips'].drop_duplicates(keep='first').to_list()\n",
    "print(f'Num counties: {len(cfips_list)}')\n",
    "print(cfips_list[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't believe I'm only noticing this now - but I wonder if there is a reason why it seems like only odd cfips are included in the dataset? Let's ignore it for now, but definitely mental note material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocks shape: (100320, 2, 4, 4)\n",
      "\n",
      "Example block:\n",
      "[[[1.0010000e+03 1.5646176e+18 3.0076818e+00 1.2490000e+03]\n",
      "  [1.0010000e+03 1.5672960e+18 2.8848701e+00 1.1980000e+03]\n",
      "  [1.0010000e+03 1.5698880e+18 3.0558431e+00 1.2690000e+03]\n",
      "  [1.0010000e+03 1.5725664e+18 2.9932332e+00 1.2430000e+03]]\n",
      "\n",
      " [[1.0010000e+03 1.5751584e+18 2.9932332e+00 1.2430000e+03]\n",
      "  [1.0010000e+03 1.5778368e+18 2.9690900e+00 1.2420000e+03]\n",
      "  [1.0010000e+03 1.5805152e+18 2.9093256e+00 1.2170000e+03]\n",
      "  [1.0010000e+03 1.5830208e+18 2.9332314e+00 1.2270000e+03]]]\n",
      "\n",
      "Original timeseries:\n",
      "[3.0076818, 2.8848701, 3.0558431, 2.9932332, 2.9932332, 2.96909, 2.9093256, 2.9332314, 3.0001674, 3.0049484, 3.0192919, 3.0838373, 3.174679, 3.2057564, 3.1938035, 3.0384164, 3.002558, 2.9472437, 3.1061056, 3.1440427, 3.2246592, 3.2270303, 3.2222881, 3.2104328, 3.2199171, 3.186722, 3.2033195, 3.2009485, 3.2863071, 3.2967808, 3.3344314, 3.3367846, 3.372082, 3.3132529, 3.3461974, 3.4379706, 3.4238517, 3.442677, 3.4638555]\n"
     ]
    }
   ],
   "source": [
    "# Get rid of unnecessary string columns: row id is redundant to cfips and \n",
    "# first_day_of_month, county and state are both redundant to cfips\n",
    "trimmed_training_df = training_df.drop(['row_id', 'county', 'state'], axis=1)\n",
    "\n",
    "# Convert first day of month to int so we don't have pandas data types\n",
    "# in our result - want to use numpy\n",
    "trimmed_training_df['first_day_of_month'] =  trimmed_training_df['first_day_of_month'].astype(int)\n",
    "\n",
    "# Data metaparameters\n",
    "block_width = max_model_order + max_forecast_horizon\n",
    "\n",
    "# Temporary holders for blocks\n",
    "blocks = []\n",
    "\n",
    "# Loop on county\n",
    "for cfips in cfips_list:\n",
    "\n",
    "    # Get data for current county\n",
    "    timeseries = trimmed_training_df[trimmed_training_df['cfips'] == cfips]\n",
    "\n",
    "    # Convert to numpy array\n",
    "    timeseries = timeseries.to_numpy()\n",
    "\n",
    "    # Loop on the timeseries index, up to the desired block with\n",
    "    # before the end\n",
    "    for i in range(len(timeseries) - (block_width - 1)):\n",
    "\n",
    "        # Get block, starting from current index\n",
    "        block = timeseries[i:(i + block_width)]\n",
    "\n",
    "        # Split block into input and forecast\n",
    "        block = np.array_split(block, [max_model_order])\n",
    "\n",
    "        # Add to list\n",
    "        blocks.append(block)\n",
    "\n",
    "# Convert the whole thing to numpy\n",
    "blocks = np.array(blocks)\n",
    "\n",
    "# Inspect a block on completion\n",
    "print(f'Blocks shape: {blocks.shape}')\n",
    "print()\n",
    "print(f'Example block:\\n{blocks[0]}')\n",
    "print()\n",
    "print(f'Original timeseries:\\n{trimmed_training_df[\"microbusiness_density\"][trimmed_training_df[\"cfips\"] == cfips_list[0]].tolist()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step would be to partition the result into working and test sets, and then within the working set partition into training and validation sets. Then permute the training and validation sets during model training. Let's leave that for the training run.\n",
    "\n",
    "<a name=\"sanity_check\"></a>\n",
    "### 4. Sanity check\n",
    "\n",
    "Last thing to do before we write this to disk is a sanity test. Let's see if we can get our dates, row_ids and cfips back into a format that matches the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dates: [1.5646176e+18 1.5672960e+18 1.5698880e+18 1.5725664e+18]\n",
      "dtype: <class 'numpy.ndarray'>\n",
      "element dtype: <class 'numpy.float64'>\n",
      "\n",
      "Test dates: [1564617600000000000 1567296000000000000 1569888000000000000\n",
      " 1572566400000000000]\n",
      "dtype: <class 'numpy.ndarray'>\n",
      "element dtype: <class 'numpy.int64'>\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 1 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   first_day_of_month  4 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 160.0 bytes\n"
     ]
    }
   ],
   "source": [
    "# Grab an example date column\n",
    "test_dates = blocks[0,0,0:,1] # type: ignore\n",
    "print(f'Test dates: {test_dates}\\ndtype: {type(test_dates)}\\nelement dtype: {type(test_dates[0])}\\n')\n",
    "\n",
    "# Cast float64 to int64\n",
    "test_dates = test_dates.astype(np.int64)\n",
    "print(f'Test dates: {test_dates}\\ndtype: {type(test_dates)}\\nelement dtype: {type(test_dates[0])}\\n')\n",
    "\n",
    "# Convert to pandas dataframe with dtype datetime64[ns] and column name 'first_day_of_month'\n",
    "test_dates_df = pd.DataFrame(pd.to_datetime(test_dates), columns=['first_day_of_month']).astype('datetime64')\n",
    "test_dates_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_day_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_day_of_month\n",
       "0         2019-08-01\n",
       "1         2019-09-01\n",
       "2         2019-10-01\n",
       "3         2019-11-01"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dates_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, looks good. A little bit convoluted to get it back but at least we know we can do it if we need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cfips: [1001. 1001. 1001. 1001.]\n",
      "dtype: <class 'numpy.ndarray'>\n",
      "element dtype: <class 'numpy.float64'>\n",
      "\n",
      "Test cfips: [1001 1001 1001 1001]\n",
      "dtype: <class 'numpy.ndarray'>\n",
      "element dtype: <class 'numpy.int64'>\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   cfips   4 non-null      int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 160.0 bytes\n"
     ]
    }
   ],
   "source": [
    "# Grab an example cfips column\n",
    "test_cfips = blocks[0,0,0:,0] # type: ignore\n",
    "print(f'Test cfips: {test_cfips}\\ndtype: {type(test_cfips)}\\nelement dtype: {type(test_cfips[0])}\\n')\n",
    "\n",
    "# Cast float64 to int64\n",
    "test_cfips = test_cfips.astype(np.int64)\n",
    "print(f'Test cfips: {test_cfips}\\ndtype: {type(test_cfips)}\\nelement dtype: {type(test_cfips[0])}\\n')\n",
    "\n",
    "# Convert to pandas dataframe with dtype int64 and column name 'cfips'\n",
    "test_cfips_df = pd.DataFrame(test_cfips, columns=['cfips']).astype('int64')\n",
    "test_cfips_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cfips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cfips\n",
       "0   1001\n",
       "1   1001\n",
       "2   1001\n",
       "3   1001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cfips_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, not too bad. From here I am confident about 'row_id' and the county and state if we need them. Row id is just a string concatenation of the cfips and the first day of the month. With the cfips, we can easily look up the county and state if we need it.\n",
    "\n",
    "<a name=\"write_to_disk\"></a>\n",
    "### 5. Write to disk\n",
    "\n",
    "Calling this good. Let's write to disk and move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_order' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Write to disk\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m output_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mconf\u001b[39m.\u001b[39mDATA_PATH\u001b[39m}\u001b[39;00m\u001b[39m/parsed_data/order\u001b[39m\u001b[39m{\u001b[39;00mmodel_order\u001b[39m}\u001b[39;00m\u001b[39m_horizon\u001b[39m\u001b[39m{\u001b[39;00mforecast_horizon\u001b[39m}\u001b[39;00m\u001b[39m.npy\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      3\u001b[0m np\u001b[39m.\u001b[39msave(output_file, blocks)\n\u001b[1;32m      5\u001b[0m \u001b[39m# Check round-trip\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_order' is not defined"
     ]
    }
   ],
   "source": [
    "# Write to disk\n",
    "output_file = f'{conf.DATA_PATH}/parsed_data/order{model_order}_horizon{forecast_horizon}.npy'\n",
    "np.save(output_file, blocks)\n",
    "\n",
    "# Check round-trip\n",
    "loaded_blocks = np.load(output_file)\n",
    "\n",
    "# Inspect\n",
    "print(f'Shape: {loaded_blocks.shape}')\n",
    "print()\n",
    "print(loaded_blocks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, looks good. Time to start making some models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"TODO\"></a>\n",
    "### 6. TODO\n",
    "1. Refactor parse into loop to generate all orders/horizon sizes of interest in one shot without manual intervention"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microbusiness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c89e0f329143aafc2740b6540b46c06e92791a1e818eb6a9ece1d952786ba476"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
